{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가장 기초적인 방법의 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d0941c35b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 재사용을 위해 랜덤값을 초기화합니다.\n",
    "torch.manual_seed(2023)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1,3],[2,6],[3,9]])\n",
    "y_train = torch.FloatTensor([[3],[6],[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.]], requires_grad=True),\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros(size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(size=(1,), requires_grad=True)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.matmul(x_train, W) + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0,  Cost:42.000000,  W_0:0.280000,  W_1:0.840000,  b:0.120000\n",
      "Epoch:  99,  Cost: 0.001313,  W_0:0.295890,  W_1:0.887671,  b:0.095607\n",
      "Epoch: 100,  Cost: 0.001306,  W_0:0.295902,  W_1:0.887705,  b:0.095339\n",
      "Epoch: 199,  Cost: 0.000749,  W_0:0.296897,  W_1:0.890691,  b:0.072190\n",
      "Epoch: 200,  Cost: 0.000745,  W_0:0.296905,  W_1:0.890717,  b:0.071988\n",
      "Epoch: 299,  Cost: 0.000427,  W_0:0.297657,  W_1:0.892971,  b:0.054509\n",
      "Epoch: 300,  Cost: 0.000424,  W_0:0.297663,  W_1:0.892990,  b:0.054356\n",
      "Epoch: 399,  Cost: 0.000243,  W_0:0.298231,  W_1:0.894692,  b:0.041158\n",
      "Epoch: 400,  Cost: 0.000242,  W_0:0.298236,  W_1:0.894707,  b:0.041043\n",
      "Epoch: 499,  Cost: 0.000139,  W_0:0.298664,  W_1:0.895992,  b:0.031078\n",
      "Epoch: 500,  Cost: 0.000138,  W_0:0.298668,  W_1:0.896004,  b:0.030990\n",
      "Epoch: 599,  Cost: 0.000079,  W_0:0.298991,  W_1:0.896974,  b:0.023466\n",
      "Epoch: 600,  Cost: 0.000079,  W_0:0.298994,  W_1:0.896982,  b:0.023400\n",
      "Epoch: 699,  Cost: 0.000045,  W_0:0.299238,  W_1:0.897715,  b:0.017718\n",
      "Epoch: 700,  Cost: 0.000045,  W_0:0.299240,  W_1:0.897722,  b:0.017669\n",
      "Epoch: 799,  Cost: 0.000026,  W_0:0.299425,  W_1:0.898275,  b:0.013379\n",
      "Epoch: 800,  Cost: 0.000026,  W_0:0.299426,  W_1:0.898280,  b:0.013341\n",
      "Epoch: 899,  Cost: 0.000015,  W_0:0.299565,  W_1:0.898697,  b:0.010102\n",
      "Epoch: 900,  Cost: 0.000015,  W_0:0.299566,  W_1:0.898701,  b:0.010074\n",
      "Epoch: 999,  Cost: 0.000008,  W_0:0.299672,  W_1:0.899016,  b:0.007628\n",
      "Epoch:1000,  Cost: 0.000008,  W_0:0.299673,  W_1:0.899019,  b:0.007606\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = torch.matmul(x_train, W) + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x)개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그출력\n",
    "    if not (epoch % 100) or (epoch % 100 == 99):\n",
    "        print(f\"Epoch:{epoch:4d},  Cost:{cost.item():9.6f},  W_0:{W[0].item():.6f},  W_1:{W[1].item():.6f},  b:{b.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.matmul(x_train, torch.zeros(size=(2,1), requires_grad=True)) + torch.zeros(size=(1,), requires_grad=True)\n",
    "mse = torch.mean((hypothesis - y_train) ** 2).item()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001305891782976687\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.matmul(x_train, torch.Tensor([[0.295890],[0.887671]])) + torch.Tensor([0.095607])\n",
    "mse = torch.mean((hypothesis - y_train) ** 2).item()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cuda_graph_capture_health_check', '_hook_for_profile', '_optimizer_step_code', '_warned_capturable_if_run_uncaptured', '_zero_grad_profile_name', 'add_param_group', 'defaults', 'load_state_dict', 'param_groups', 'state', 'state_dict', 'step', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {tensor([[0.2997],\n",
      "        [0.8990]], requires_grad=True): {'momentum_buffer': None}, tensor([0.0076], requires_grad=True): {'momentum_buffer': None}})\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
