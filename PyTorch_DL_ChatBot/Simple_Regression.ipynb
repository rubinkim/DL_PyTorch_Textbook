{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 가장 기초적인 방법의 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e0b3bce4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 재사용을 위해 랜덤값을 초기화합니다.\n",
    "torch.manual_seed(2023)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[-1,3],[3,7],[4,9]])\n",
    "y_train = torch.FloatTensor([[3],[6],[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.],\n",
       "         [0.]], requires_grad=True),\n",
       " tensor([0.], requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.zeros(size=(2,1), requires_grad=True)\n",
    "b = torch.zeros(size=(1,), requires_grad=True)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.matmul(x_train, W) + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "optimizer = optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0,                   W_0:0.000000,  W_1:0.000000,  b:0.000000\n",
      "Epoch:   0,  Cost:42.000000,  W_0:0.340000,  W_1:0.880000,  b:0.120000\n",
      "\n",
      "Epoch:  99,                   W_0:0.004593,  W_1:0.927964,  b:0.143060\n",
      "Epoch:  99,  Cost: 0.222988,  W_0:0.004008,  W_1:0.928276,  b:0.142473\n",
      "\n",
      "Epoch: 100,                   W_0:0.004008,  W_1:0.928276,  b:0.142473\n",
      "Epoch: 100,  Cost: 0.222909,  W_0:0.003435,  W_1:0.928584,  b:0.141882\n",
      "\n",
      "Epoch: 199,                   W_0:-0.026794,  W_1:0.949597,  b:0.075048\n",
      "Epoch: 199,  Cost: 0.216787,  W_0:-0.027007,  W_1:0.949777,  b:0.074337\n",
      "\n",
      "Epoch: 200,                   W_0:-0.027007,  W_1:0.949777,  b:0.074337\n",
      "Epoch: 200,  Cost: 0.216728,  W_0:-0.027219,  W_1:0.949957,  b:0.073625\n",
      "\n",
      "Epoch: 299,                   W_0:-0.046907,  W_1:0.967128,  b:0.004012\n",
      "Epoch: 299,  Cost: 0.211029,  W_0:-0.047104,  W_1:0.967301,  b:0.003305\n",
      "\n",
      "Epoch: 300,                   W_0:-0.047104,  W_1:0.967301,  b:0.003305\n",
      "Epoch: 300,  Cost: 0.210972,  W_0:-0.047300,  W_1:0.967474,  b:0.002599\n",
      "\n",
      "Epoch: 399,                   W_0:-0.066349,  W_1:0.984284,  b:-0.066220\n",
      "Epoch: 399,  Cost: 0.205424,  W_0:-0.066541,  W_1:0.984454,  b:-0.066917\n",
      "\n",
      "Epoch: 400,                   W_0:-0.066541,  W_1:0.984454,  b:-0.066917\n",
      "Epoch: 400,  Cost: 0.205369,  W_0:-0.066734,  W_1:0.984624,  b:-0.067615\n",
      "\n",
      "Epoch: 499,                   W_0:-0.085515,  W_1:1.001205,  b:-0.135518\n",
      "Epoch: 499,  Cost: 0.199969,  W_0:-0.085705,  W_1:1.001373,  b:-0.136207\n",
      "\n",
      "Epoch: 500,                   W_0:-0.085705,  W_1:1.001373,  b:-0.136207\n",
      "Epoch: 500,  Cost: 0.199915,  W_0:-0.085895,  W_1:1.001541,  b:-0.136895\n",
      "\n",
      "Epoch: 599,                   W_0:-0.104424,  W_1:1.017899,  b:-0.203891\n",
      "Epoch: 599,  Cost: 0.194658,  W_0:-0.104612,  W_1:1.018065,  b:-0.204570\n",
      "\n",
      "Epoch: 600,                   W_0:-0.104612,  W_1:1.018065,  b:-0.204570\n",
      "Epoch: 600,  Cost: 0.194605,  W_0:-0.104800,  W_1:1.018231,  b:-0.205249\n",
      "\n",
      "Epoch: 699,                   W_0:-0.123081,  W_1:1.034370,  b:-0.271349\n",
      "Epoch: 699,  Cost: 0.189488,  W_0:-0.123266,  W_1:1.034534,  b:-0.272019\n",
      "\n",
      "Epoch: 700,                   W_0:-0.123266,  W_1:1.034534,  b:-0.272019\n",
      "Epoch: 700,  Cost: 0.189437,  W_0:-0.123451,  W_1:1.034698,  b:-0.272689\n",
      "\n",
      "Epoch: 799,                   W_0:-0.141488,  W_1:1.050621,  b:-0.337906\n",
      "Epoch: 799,  Cost: 0.184456,  W_0:-0.141671,  W_1:1.050783,  b:-0.338567\n",
      "\n",
      "Epoch: 800,                   W_0:-0.141671,  W_1:1.050783,  b:-0.338567\n",
      "Epoch: 800,  Cost: 0.184406,  W_0:-0.141854,  W_1:1.050944,  b:-0.339228\n",
      "\n",
      "Epoch: 899,                   W_0:-0.159649,  W_1:1.066655,  b:-0.403573\n",
      "Epoch: 899,  Cost: 0.179557,  W_0:-0.159830,  W_1:1.066814,  b:-0.404225\n",
      "\n",
      "Epoch: 900,                   W_0:-0.159830,  W_1:1.066814,  b:-0.404225\n",
      "Epoch: 900,  Cost: 0.179509,  W_0:-0.160010,  W_1:1.066974,  b:-0.404877\n",
      "\n",
      "Epoch: 999,                   W_0:-0.177568,  W_1:1.082474,  b:-0.468362\n",
      "Epoch: 999,  Cost: 0.174788,  W_0:-0.177746,  W_1:1.082632,  b:-0.469005\n",
      "\n",
      "Epoch:1000,                   W_0:-0.177746,  W_1:1.082632,  b:-0.469005\n",
      "Epoch:1000,  Cost: 0.174741,  W_0:-0.177923,  W_1:1.082789,  b:-0.469649\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    hypothesis = torch.matmul(x_train, W) + b\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    # cost로 H(x)개선\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if not (epoch % 100) or (epoch % 100 == 99):\n",
    "        print()\n",
    "        print(f\"Epoch:{epoch:4d},                   W_0:{W[0].item():.6f},  W_1:{W[1].item():.6f},  b:{b.item():.6f}\")\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그출력\n",
    "    if not (epoch % 100) or (epoch % 100 == 99):\n",
    "        print(f\"Epoch:{epoch:4d},  Cost:{cost.item():9.6f},  W_0:{W[0].item():.6f},  W_1:{W[1].item():.6f},  b:{b.item():.6f}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 테스트 값이 [5, 12]일 떄의 예측 값 : 11.634\n"
     ]
    }
   ],
   "source": [
    "test_var = torch.FloatTensor([[5, 12]])\n",
    "with torch.no_grad():\n",
    "    pred_y = torch.matmul(test_var, W) + b\n",
    "    print(f\"훈련 후 테스트 값이 [5, 12]일 떄의 예측 값 : {pred_y.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.0\n"
     ]
    }
   ],
   "source": [
    "hypothesis = torch.matmul(x_train, torch.zeros(size=(2,1), requires_grad=True)) + torch.zeros(size=(1,), requires_grad=True)\n",
    "mse = torch.mean((hypothesis - y_train) ** 2).item()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {tensor([[-0.1779],\n",
      "        [ 1.0828]], requires_grad=True): {'momentum_buffer': None}, tensor([-0.4696], requires_grad=True): {'momentum_buffer': None}})\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Module로 구현하는 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[-1,3],[3,7],[4,9]])\n",
    "y_train = torch.FloatTensor([[3],[6],[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = 2, 1\n",
    "\n",
    "model = nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1004,  0.3112]], requires_grad=True)\n",
      "\n",
      "Parameter containing:\n",
      "tensor([0.6338], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0,  Cost: 16.516907,  W_0:0.119613,  W_1:0.858689,  b:0.705695\n",
      "Epoch:  99,  Cost:  0.262315,  W_0:0.118300,  W_1:0.820457,  b:0.607471\n",
      "Epoch: 100,  Cost:  0.262244,  W_0:0.118131,  W_1:0.820632,  b:0.606665\n",
      "Epoch: 199,  Cost:  0.255344,  W_0:0.098107,  W_1:0.839062,  b:0.528644\n",
      "Epoch: 200,  Cost:  0.255275,  W_0:0.097894,  W_1:0.839251,  b:0.527866\n",
      "Epoch: 299,  Cost:  0.248562,  W_0:0.076796,  W_1:0.857905,  b:0.451373\n",
      "Epoch: 300,  Cost:  0.248495,  W_0:0.076584,  W_1:0.858092,  b:0.450606\n",
      "Epoch: 399,  Cost:  0.241961,  W_0:0.055719,  W_1:0.876514,  b:0.375154\n",
      "Epoch: 400,  Cost:  0.241895,  W_0:0.055510,  W_1:0.876699,  b:0.374397\n",
      "Epoch: 499,  Cost:  0.235535,  W_0:0.034922,  W_1:0.894876,  b:0.299955\n",
      "Epoch: 500,  Cost:  0.235471,  W_0:0.034715,  W_1:0.895058,  b:0.299208\n",
      "Epoch: 599,  Cost:  0.229279,  W_0:0.014402,  W_1:0.912992,  b:0.225761\n",
      "Epoch: 600,  Cost:  0.229218,  W_0:0.014199,  W_1:0.913171,  b:0.225024\n",
      "Epoch: 699,  Cost:  0.223190,  W_0:-0.005843,  W_1:0.930865,  b:0.152559\n",
      "Epoch: 700,  Cost:  0.223130,  W_0:-0.006044,  W_1:0.931043,  b:0.151832\n",
      "Epoch: 799,  Cost:  0.217262,  W_0:-0.025817,  W_1:0.948500,  b:0.080335\n",
      "Epoch: 800,  Cost:  0.217204,  W_0:-0.026016,  W_1:0.948675,  b:0.079618\n",
      "Epoch: 899,  Cost:  0.211493,  W_0:-0.045525,  W_1:0.965899,  b:0.009077\n",
      "Epoch: 900,  Cost:  0.211435,  W_0:-0.045720,  W_1:0.966072,  b:0.008369\n",
      "Epoch: 999,  Cost:  0.205875,  W_0:-0.064969,  W_1:0.983065,  b:-0.061228\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)     # PyTorch에서 제공하는 mse\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    W_0 = list(model.parameters())[0][0][0]   \n",
    "    W_1 = list(model.parameters())[0][0][1]\n",
    "    b   = list(model.parameters())[1][0]\n",
    "    # 100번마다 로그출력\n",
    "    if not (epoch % 100) or (epoch % 100 == 99):\n",
    "        print(f\"Epoch:{epoch:4d},  Cost:{cost.item():10.6f},  W_0:{W_0.item():.6f},  W_1:{W_1.item():.6f},  b:{b.item():.6f}\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 [5,12]일 때의 예측값 : 11.411\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[5, 12]])\n",
    "pred_y = model(new_var)\n",
    "print(f\"훈련 후 입력이 [5,12]일 때의 예측값 : {pred_y.item():.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Module class로 구현하는 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[-1,3],[3,7],[4,9]])\n",
    "y_train = torch.FloatTensor([[3],[6],[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=2, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)    # forward 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    0,  Cost :  30.524385,  W_0 : 0.267,  W_1 : 0.807,  b : 0.794\n",
      "Epoch :   99,  Cost :   0.273449,  W_0 : 0.156,  W_1 : 0.789,  b : 0.729\n",
      "Epoch :  100,  Cost :   0.273374,  W_0 : 0.156,  W_1 : 0.789,  b : 0.728\n",
      "Epoch :  199,  Cost :   0.266173,  W_0 : 0.132,  W_1 : 0.809,  b : 0.650\n",
      "Epoch :  200,  Cost :   0.266101,  W_0 : 0.132,  W_1 : 0.810,  b : 0.649\n",
      "Epoch :  299,  Cost :   0.259103,  W_0 : 0.110,  W_1 : 0.829,  b : 0.571\n",
      "Epoch :  300,  Cost :   0.259033,  W_0 : 0.110,  W_1 : 0.829,  b : 0.570\n",
      "Epoch :  399,  Cost :   0.252222,  W_0 : 0.088,  W_1 : 0.848,  b : 0.493\n",
      "Epoch :  400,  Cost :   0.252154,  W_0 : 0.088,  W_1 : 0.848,  b : 0.492\n",
      "Epoch :  499,  Cost :   0.245523,  W_0 : 0.067,  W_1 : 0.866,  b : 0.416\n",
      "Epoch :  500,  Cost :   0.245457,  W_0 : 0.067,  W_1 : 0.867,  b : 0.416\n",
      "Epoch :  599,  Cost :   0.239003,  W_0 : 0.046,  W_1 : 0.885,  b : 0.341\n",
      "Epoch :  600,  Cost :   0.238939,  W_0 : 0.046,  W_1 : 0.885,  b : 0.340\n",
      "Epoch :  699,  Cost :   0.232655,  W_0 : 0.026,  W_1 : 0.903,  b : 0.266\n",
      "Epoch :  700,  Cost :   0.232593,  W_0 : 0.025,  W_1 : 0.903,  b : 0.265\n",
      "Epoch :  799,  Cost :   0.226476,  W_0 : 0.005,  W_1 : 0.921,  b : 0.192\n",
      "Epoch :  800,  Cost :   0.226415,  W_0 : 0.005,  W_1 : 0.921,  b : 0.191\n",
      "Epoch :  899,  Cost :   0.220462,  W_0 : -0.015,  W_1 : 0.939,  b : 0.119\n",
      "Epoch :  900,  Cost :   0.220402,  W_0 : -0.015,  W_1 : 0.939,  b : 0.119\n",
      "Epoch :  999,  Cost :   0.214607,  W_0 : -0.035,  W_1 : 0.956,  b : 0.048\n",
      "Epoch : 1000,  Cost :   0.214549,  W_0 : -0.035,  W_1 : 0.957,  b : 0.047\n",
      "Epoch : 1099,  Cost :   0.208907,  W_0 : -0.054,  W_1 : 0.974,  b : -0.023\n",
      "Epoch : 1100,  Cost :   0.208851,  W_0 : -0.055,  W_1 : 0.974,  b : -0.024\n",
      "Epoch : 1199,  Cost :   0.203359,  W_0 : -0.074,  W_1 : 0.991,  b : -0.093\n",
      "Epoch : 1200,  Cost :   0.203304,  W_0 : -0.074,  W_1 : 0.991,  b : -0.094\n",
      "Epoch : 1299,  Cost :   0.197958,  W_0 : -0.093,  W_1 : 1.008,  b : -0.162\n",
      "Epoch : 1300,  Cost :   0.197905,  W_0 : -0.093,  W_1 : 1.008,  b : -0.163\n",
      "Epoch : 1399,  Cost :   0.192701,  W_0 : -0.112,  W_1 : 1.024,  b : -0.230\n",
      "Epoch : 1400,  Cost :   0.192649,  W_0 : -0.112,  W_1 : 1.024,  b : -0.231\n",
      "Epoch : 1499,  Cost :   0.187583,  W_0 : -0.130,  W_1 : 1.041,  b : -0.297\n",
      "Epoch : 1500,  Cost :   0.187533,  W_0 : -0.130,  W_1 : 1.041,  b : -0.298\n",
      "Epoch : 1599,  Cost :   0.182601,  W_0 : -0.149,  W_1 : 1.057,  b : -0.363\n",
      "Epoch : 1600,  Cost :   0.182552,  W_0 : -0.149,  W_1 : 1.057,  b : -0.364\n",
      "Epoch : 1699,  Cost :   0.177751,  W_0 : -0.167,  W_1 : 1.073,  b : -0.429\n",
      "Epoch : 1700,  Cost :   0.177703,  W_0 : -0.167,  W_1 : 1.073,  b : -0.429\n",
      "Epoch : 1799,  Cost :   0.173031,  W_0 : -0.184,  W_1 : 1.089,  b : -0.493\n",
      "Epoch : 1800,  Cost :   0.172984,  W_0 : -0.185,  W_1 : 1.089,  b : -0.494\n",
      "Epoch : 1899,  Cost :   0.168435,  W_0 : -0.202,  W_1 : 1.104,  b : -0.557\n",
      "Epoch : 1900,  Cost :   0.168390,  W_0 : -0.202,  W_1 : 1.104,  b : -0.557\n",
      "Epoch : 1999,  Cost :   0.163962,  W_0 : -0.219,  W_1 : 1.119,  b : -0.619\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model_params = list(model.parameters())\n",
    "    W_0, W_1, b = model_params[0][0][0], model_params[0][0][1], model_params[1][0]\n",
    "    if not(epoch % 100) or (epoch % 100 == 99):\n",
    "        print(f\"Epoch : {epoch:4d},  Cost : {cost.item():10.6f},  W_0 : {W_0.item():.3f},  W_1 : {W_1.item():.3f},  b : {b.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 [5, 12]일 때의 예측값 : 11.716\n"
     ]
    }
   ],
   "source": [
    "new_var = torch.FloatTensor([[5, 12]])\n",
    "with torch.no_grad():\n",
    "    pred_y = model(new_var)\n",
    "    print(f\"훈련 후 입력이 [5, 12]일 때의 예측값 : {pred_y.item():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
